{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Machine Learning toolkit\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlite3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"./beer_data.sqlite\")\n",
    "c = con.cursor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "beers_df = pd.read_sql_query(\"SELECT * FROM taste_profiles\", con)\n",
    "beer_stats = pd.read_sql_query(\"SELECT * FROM beer_stats\", con).drop('Full_Beer_Name', axis=1, inplace=True)\n",
    "reviews_df = pd.read_sql_query(\"SELECT * FROM reviews\", con)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "     Style  ABV  Min_IBU  Max_IBU  Astringency  Body  Alcohol  Bitter  Sweet  \\\n0  Altbier  5.3       25       50           13    32        9      47     74   \n1  Altbier  7.2       25       50           12    57       18      33     55   \n2  Altbier  5.0       25       50           14    37        6      42     43   \n3  Altbier  8.5       25       50           13    55       31      47    101   \n4  Altbier  7.2       25       50           25    51       26      44     45   \n\n   Sour  Salty  Fruits  Hoppy  Spices  Malty  \n0    33      0      33     57       8    111  \n1    16      0      24     35      12     84  \n2    11      0      10     54       4     62  \n3    18      1      49     40      16    119  \n4     9      1      11     51      20     95  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Style</th>\n      <th>ABV</th>\n      <th>Min_IBU</th>\n      <th>Max_IBU</th>\n      <th>Astringency</th>\n      <th>Body</th>\n      <th>Alcohol</th>\n      <th>Bitter</th>\n      <th>Sweet</th>\n      <th>Sour</th>\n      <th>Salty</th>\n      <th>Fruits</th>\n      <th>Hoppy</th>\n      <th>Spices</th>\n      <th>Malty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Altbier</td>\n      <td>5.3</td>\n      <td>25</td>\n      <td>50</td>\n      <td>13</td>\n      <td>32</td>\n      <td>9</td>\n      <td>47</td>\n      <td>74</td>\n      <td>33</td>\n      <td>0</td>\n      <td>33</td>\n      <td>57</td>\n      <td>8</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Altbier</td>\n      <td>7.2</td>\n      <td>25</td>\n      <td>50</td>\n      <td>12</td>\n      <td>57</td>\n      <td>18</td>\n      <td>33</td>\n      <td>55</td>\n      <td>16</td>\n      <td>0</td>\n      <td>24</td>\n      <td>35</td>\n      <td>12</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Altbier</td>\n      <td>5.0</td>\n      <td>25</td>\n      <td>50</td>\n      <td>14</td>\n      <td>37</td>\n      <td>6</td>\n      <td>42</td>\n      <td>43</td>\n      <td>11</td>\n      <td>0</td>\n      <td>10</td>\n      <td>54</td>\n      <td>4</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Altbier</td>\n      <td>8.5</td>\n      <td>25</td>\n      <td>50</td>\n      <td>13</td>\n      <td>55</td>\n      <td>31</td>\n      <td>47</td>\n      <td>101</td>\n      <td>18</td>\n      <td>1</td>\n      <td>49</td>\n      <td>40</td>\n      <td>16</td>\n      <td>119</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Altbier</td>\n      <td>7.2</td>\n      <td>25</td>\n      <td>50</td>\n      <td>25</td>\n      <td>51</td>\n      <td>26</td>\n      <td>44</td>\n      <td>45</td>\n      <td>9</td>\n      <td>1</td>\n      <td>11</td>\n      <td>51</td>\n      <td>20</td>\n      <td>95</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop beer and brewery names (for simple test model)\n",
    "beers_df.drop(['Full_Beer_Name', 'Brewery'], axis=1, inplace=True)\n",
    "beers_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "     Style       ABV   Min_IBU  Max_IBU  Astringency      Body   Alcohol  \\\n0  Altbier  0.092174  0.384615      0.5     0.117117  0.288288  0.081081   \n1  Altbier  0.125217  0.384615      0.5     0.142857  0.678571  0.214286   \n2  Altbier  0.086957  0.384615      0.5     0.225806  0.596774  0.096774   \n3  Altbier  0.147826  0.384615      0.5     0.101695  0.457627  0.254237   \n4  Altbier  0.125217  0.384615      0.5     0.255319  0.531915  0.265957   \n\n     Bitter     Sweet      Sour  Salty    Fruits     Hoppy    Spices  Malty  \n0  0.423423  0.666667  0.297297    0.0  0.297297  0.513514  0.072072    1.0  \n1  0.392857  0.654762  0.190476    0.0  0.285714  0.416667  0.142857    1.0  \n2  0.677419  0.693548  0.177419    0.0  0.161290  0.870968  0.064516    1.0  \n3  0.389831  0.847458  0.144068    0.0  0.406780  0.330508  0.127119    1.0  \n4  0.457447  0.468085  0.085106    0.0  0.106383  0.531915  0.202128    1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Style</th>\n      <th>ABV</th>\n      <th>Min_IBU</th>\n      <th>Max_IBU</th>\n      <th>Astringency</th>\n      <th>Body</th>\n      <th>Alcohol</th>\n      <th>Bitter</th>\n      <th>Sweet</th>\n      <th>Sour</th>\n      <th>Salty</th>\n      <th>Fruits</th>\n      <th>Hoppy</th>\n      <th>Spices</th>\n      <th>Malty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Altbier</td>\n      <td>0.092174</td>\n      <td>0.384615</td>\n      <td>0.5</td>\n      <td>0.117117</td>\n      <td>0.288288</td>\n      <td>0.081081</td>\n      <td>0.423423</td>\n      <td>0.666667</td>\n      <td>0.297297</td>\n      <td>0.0</td>\n      <td>0.297297</td>\n      <td>0.513514</td>\n      <td>0.072072</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Altbier</td>\n      <td>0.125217</td>\n      <td>0.384615</td>\n      <td>0.5</td>\n      <td>0.142857</td>\n      <td>0.678571</td>\n      <td>0.214286</td>\n      <td>0.392857</td>\n      <td>0.654762</td>\n      <td>0.190476</td>\n      <td>0.0</td>\n      <td>0.285714</td>\n      <td>0.416667</td>\n      <td>0.142857</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Altbier</td>\n      <td>0.086957</td>\n      <td>0.384615</td>\n      <td>0.5</td>\n      <td>0.225806</td>\n      <td>0.596774</td>\n      <td>0.096774</td>\n      <td>0.677419</td>\n      <td>0.693548</td>\n      <td>0.177419</td>\n      <td>0.0</td>\n      <td>0.161290</td>\n      <td>0.870968</td>\n      <td>0.064516</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Altbier</td>\n      <td>0.147826</td>\n      <td>0.384615</td>\n      <td>0.5</td>\n      <td>0.101695</td>\n      <td>0.457627</td>\n      <td>0.254237</td>\n      <td>0.389831</td>\n      <td>0.847458</td>\n      <td>0.144068</td>\n      <td>0.0</td>\n      <td>0.406780</td>\n      <td>0.330508</td>\n      <td>0.127119</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Altbier</td>\n      <td>0.125217</td>\n      <td>0.384615</td>\n      <td>0.5</td>\n      <td>0.255319</td>\n      <td>0.531915</td>\n      <td>0.265957</td>\n      <td>0.457447</td>\n      <td>0.468085</td>\n      <td>0.085106</td>\n      <td>0.0</td>\n      <td>0.106383</td>\n      <td>0.531915</td>\n      <td>0.202128</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "def scale_col_by_row(df, cols):\n",
    "    # Scale values by row\n",
    "    scaled_cols = pd.DataFrame(scaler.fit_transform(df[cols].T).T, columns=cols)\n",
    "    df[cols] = scaled_cols\n",
    "    return df\n",
    "\n",
    "def scale_col_by_col(df, cols):\n",
    "    # Scale values by column\n",
    "    scaled_cols = pd.DataFrame(scaler.fit_transform(df[cols]), columns=cols)\n",
    "    df[cols] = scaled_cols\n",
    "    return df\n",
    "\n",
    "# Scale values in tasting profile features (across rows)\n",
    "beers_df = scale_col_by_row(beers_df, beers_df.columns[4:15])\n",
    "\n",
    "# Scale values in tasting profile features (across columns)\n",
    "beers_df = scale_col_by_col(beers_df, beers_df.columns[4:15])\n",
    "\n",
    "# Scale values in chemical features (across columns)\n",
    "beers_df = scale_col_by_col(beers_df, beers_df.columns[1:4])\n",
    "\n",
    "# Peak at re-scaled data\n",
    "beers_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Style_Altbier  Style_Barleywine  Style_Bitter  Style_Blonde Ale  \\\n0            1.0               0.0           0.0               0.0   \n1            1.0               0.0           0.0               0.0   \n2            1.0               0.0           0.0               0.0   \n3            1.0               0.0           0.0               0.0   \n4            1.0               0.0           0.0               0.0   \n\n   Style_Bock  Style_Brown Ale  Style_Chile Beer  Style_Cream Ale  \\\n0         0.0              0.0               0.0              0.0   \n1         0.0              0.0               0.0              0.0   \n2         0.0              0.0               0.0              0.0   \n3         0.0              0.0               0.0              0.0   \n4         0.0              0.0               0.0              0.0   \n\n   Style_Dubbel  Style_Farmhouse Ale  ...  Style_Scotch Ale / Wee Heavy  \\\n0           0.0                  0.0  ...                           0.0   \n1           0.0                  0.0  ...                           0.0   \n2           0.0                  0.0  ...                           0.0   \n3           0.0                  0.0  ...                           0.0   \n4           0.0                  0.0  ...                           0.0   \n\n   Style_Scottish Ale  Style_Smoked Beer  Style_Sour  Style_Stout  \\\n0                 0.0                0.0         0.0          0.0   \n1                 0.0                0.0         0.0          0.0   \n2                 0.0                0.0         0.0          0.0   \n3                 0.0                0.0         0.0          0.0   \n4                 0.0                0.0         0.0          0.0   \n\n   Style_Strong Ale  Style_Tripel  Style_Wheat Beer  Style_Wild Ale  \\\n0               0.0           0.0               0.0             0.0   \n1               0.0           0.0               0.0             0.0   \n2               0.0           0.0               0.0             0.0   \n3               0.0           0.0               0.0             0.0   \n4               0.0           0.0               0.0             0.0   \n\n   Style_Winter Warmer  \n0                  0.0  \n1                  0.0  \n2                  0.0  \n3                  0.0  \n4                  0.0  \n\n[5 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Style_Altbier</th>\n      <th>Style_Barleywine</th>\n      <th>Style_Bitter</th>\n      <th>Style_Blonde Ale</th>\n      <th>Style_Bock</th>\n      <th>Style_Brown Ale</th>\n      <th>Style_Chile Beer</th>\n      <th>Style_Cream Ale</th>\n      <th>Style_Dubbel</th>\n      <th>Style_Farmhouse Ale</th>\n      <th>...</th>\n      <th>Style_Scotch Ale / Wee Heavy</th>\n      <th>Style_Scottish Ale</th>\n      <th>Style_Smoked Beer</th>\n      <th>Style_Sour</th>\n      <th>Style_Stout</th>\n      <th>Style_Strong Ale</th>\n      <th>Style_Tripel</th>\n      <th>Style_Wheat Beer</th>\n      <th>Style_Wild Ale</th>\n      <th>Style_Winter Warmer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit the encoder and produce encoded DataFrame\n",
    "encode_df = pd.DataFrame(enc.fit_transform(beers_df['Style'].values.reshape(-1,1)))\n",
    "\n",
    "# Rename encoded columns\n",
    "encode_df.columns = enc.get_feature_names(['Style'])\n",
    "encode_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "           ABV   Min_IBU  Max_IBU  Astringency      Body   Alcohol    Bitter  \\\n0     0.092174  0.384615      0.5     0.117117  0.288288  0.081081  0.423423   \n1     0.125217  0.384615      0.5     0.142857  0.678571  0.214286  0.392857   \n2     0.086957  0.384615      0.5     0.225806  0.596774  0.096774  0.677419   \n3     0.147826  0.384615      0.5     0.101695  0.457627  0.254237  0.389831   \n4     0.125217  0.384615      0.5     0.255319  0.531915  0.265957  0.457447   \n...        ...       ...      ...          ...       ...       ...       ...   \n3192  0.153043  0.538462      0.5     0.202703  0.500000  0.324324  0.472973   \n3193  0.104348  0.538462      0.5     0.107143  0.221429  0.164286  0.114286   \n3194  0.118261  0.538462      0.5     0.083333  0.458333  0.250000  0.197917   \n3195  0.130435  0.538462      0.5     0.100000  0.327273  0.454545  0.636364   \n3196  0.149565  0.538462      0.5     0.054054  0.337838  0.331081  0.087838   \n\n         Sweet      Sour  Salty  ...  Style_Scotch Ale / Wee Heavy  \\\n0     0.666667  0.297297    0.0  ...                           0.0   \n1     0.654762  0.190476    0.0  ...                           0.0   \n2     0.693548  0.177419    0.0  ...                           0.0   \n3     0.847458  0.144068    0.0  ...                           0.0   \n4     0.468085  0.085106    0.0  ...                           0.0   \n...        ...       ...    ...  ...                           ...   \n3192  0.621622  0.256757    0.0  ...                           0.0   \n3193  0.385714  0.307143    0.0  ...                           0.0   \n3194  0.541667  0.218750    0.0  ...                           0.0   \n3195  0.654545  0.536364    0.0  ...                           0.0   \n3196  0.479730  0.114865    0.0  ...                           0.0   \n\n      Style_Scottish Ale  Style_Smoked Beer  Style_Sour  Style_Stout  \\\n0                    0.0                0.0         0.0          0.0   \n1                    0.0                0.0         0.0          0.0   \n2                    0.0                0.0         0.0          0.0   \n3                    0.0                0.0         0.0          0.0   \n4                    0.0                0.0         0.0          0.0   \n...                  ...                ...         ...          ...   \n3192                 0.0                0.0         0.0          0.0   \n3193                 0.0                0.0         0.0          0.0   \n3194                 0.0                0.0         0.0          0.0   \n3195                 0.0                0.0         0.0          0.0   \n3196                 0.0                0.0         0.0          0.0   \n\n      Style_Strong Ale  Style_Tripel  Style_Wheat Beer  Style_Wild Ale  \\\n0                  0.0           0.0               0.0             0.0   \n1                  0.0           0.0               0.0             0.0   \n2                  0.0           0.0               0.0             0.0   \n3                  0.0           0.0               0.0             0.0   \n4                  0.0           0.0               0.0             0.0   \n...                ...           ...               ...             ...   \n3192               0.0           0.0               0.0             0.0   \n3193               0.0           0.0               0.0             0.0   \n3194               0.0           0.0               0.0             0.0   \n3195               0.0           0.0               0.0             0.0   \n3196               0.0           0.0               0.0             0.0   \n\n      Style_Winter Warmer  \n0                     0.0  \n1                     0.0  \n2                     0.0  \n3                     0.0  \n4                     0.0  \n...                   ...  \n3192                  1.0  \n3193                  1.0  \n3194                  1.0  \n3195                  1.0  \n3196                  1.0  \n\n[3197 rows x 52 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABV</th>\n      <th>Min_IBU</th>\n      <th>Max_IBU</th>\n      <th>Astringency</th>\n      <th>Body</th>\n      <th>Alcohol</th>\n      <th>Bitter</th>\n      <th>Sweet</th>\n      <th>Sour</th>\n      <th>Salty</th>\n      <th>...</th>\n      <th>Style_Scotch Ale / Wee Heavy</th>\n      <th>Style_Scottish Ale</th>\n      <th>Style_Smoked Beer</th>\n      <th>Style_Sour</th>\n      <th>Style_Stout</th>\n      <th>Style_Strong Ale</th>\n      <th>Style_Tripel</th>\n      <th>Style_Wheat Beer</th>\n      <th>Style_Wild Ale</th>\n      <th>Style_Winter Warmer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.092174</td>\n      <td>0.384615</td>\n      <td>0.5</td>\n      <td>0.117117</td>\n      <td>0.288288</td>\n      <td>0.081081</td>\n      <td>0.423423</td>\n      <td>0.666667</td>\n      <td>0.297297</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.125217</td>\n      <td>0.384615</td>\n      <td>0.5</td>\n      <td>0.142857</td>\n      <td>0.678571</td>\n      <td>0.214286</td>\n      <td>0.392857</td>\n      <td>0.654762</td>\n      <td>0.190476</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.086957</td>\n      <td>0.384615</td>\n      <td>0.5</td>\n      <td>0.225806</td>\n      <td>0.596774</td>\n      <td>0.096774</td>\n      <td>0.677419</td>\n      <td>0.693548</td>\n      <td>0.177419</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.147826</td>\n      <td>0.384615</td>\n      <td>0.5</td>\n      <td>0.101695</td>\n      <td>0.457627</td>\n      <td>0.254237</td>\n      <td>0.389831</td>\n      <td>0.847458</td>\n      <td>0.144068</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.125217</td>\n      <td>0.384615</td>\n      <td>0.5</td>\n      <td>0.255319</td>\n      <td>0.531915</td>\n      <td>0.265957</td>\n      <td>0.457447</td>\n      <td>0.468085</td>\n      <td>0.085106</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3192</th>\n      <td>0.153043</td>\n      <td>0.538462</td>\n      <td>0.5</td>\n      <td>0.202703</td>\n      <td>0.500000</td>\n      <td>0.324324</td>\n      <td>0.472973</td>\n      <td>0.621622</td>\n      <td>0.256757</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3193</th>\n      <td>0.104348</td>\n      <td>0.538462</td>\n      <td>0.5</td>\n      <td>0.107143</td>\n      <td>0.221429</td>\n      <td>0.164286</td>\n      <td>0.114286</td>\n      <td>0.385714</td>\n      <td>0.307143</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3194</th>\n      <td>0.118261</td>\n      <td>0.538462</td>\n      <td>0.5</td>\n      <td>0.083333</td>\n      <td>0.458333</td>\n      <td>0.250000</td>\n      <td>0.197917</td>\n      <td>0.541667</td>\n      <td>0.218750</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3195</th>\n      <td>0.130435</td>\n      <td>0.538462</td>\n      <td>0.5</td>\n      <td>0.100000</td>\n      <td>0.327273</td>\n      <td>0.454545</td>\n      <td>0.636364</td>\n      <td>0.654545</td>\n      <td>0.536364</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3196</th>\n      <td>0.149565</td>\n      <td>0.538462</td>\n      <td>0.5</td>\n      <td>0.054054</td>\n      <td>0.337838</td>\n      <td>0.331081</td>\n      <td>0.087838</td>\n      <td>0.479730</td>\n      <td>0.114865</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3197 rows × 52 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two DataFrames together and drop the Style column\n",
    "encoded_styles_df = beers_df.merge(encode_df,left_index=True,right_index=True).drop(\"Style\",1)\n",
    "encoded_styles_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = encoded_styles_df[encoded_styles_df.columns[14:]].values\n",
    "X = encoded_styles_df[encoded_styles_df.columns[:14]].values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=78)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"./ML_Weight_Checkpoints/\", exist_ok=True)\n",
    "checkpoint_path = \"./ML_Weight_Checkpoints/seg1_basic_model.h5\"\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 15)                225       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                192       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 38)                342       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 863\n",
      "Trainable params: 863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 15\n",
    "hidden_nodes_layer2 = 12\n",
    "hidden_nodes_layer3 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=38, activation=\"softmax\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "75/75 [==============================] - 1s 3ms/step - loss: 3.6177 - accuracy: 0.0601\n",
      "Epoch 2/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 3.5118 - accuracy: 0.0526\n",
      "Epoch 3/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 3.2465 - accuracy: 0.1489\n",
      "Epoch 4/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.9868 - accuracy: 0.2015\n",
      "Epoch 5/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.8416 - accuracy: 0.2211\n",
      "Epoch 6/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.7359 - accuracy: 0.2616\n",
      "Epoch 7/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.6448 - accuracy: 0.2908\n",
      "Epoch 8/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.5622 - accuracy: 0.2970\n",
      "Epoch 9/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.4823 - accuracy: 0.3100\n",
      "Epoch 10/200\n",
      "65/75 [=========================>....] - ETA: 0s - loss: 2.4231 - accuracy: 0.3173\n",
      "Epoch 10: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.4110 - accuracy: 0.3229\n",
      "Epoch 11/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.3443 - accuracy: 0.3388\n",
      "Epoch 12/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.2853 - accuracy: 0.3454\n",
      "Epoch 13/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.2304 - accuracy: 0.3517\n",
      "Epoch 14/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.1808 - accuracy: 0.3554\n",
      "Epoch 15/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.1389 - accuracy: 0.3605\n",
      "Epoch 16/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.0947 - accuracy: 0.3675\n",
      "Epoch 17/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.0592 - accuracy: 0.3746\n",
      "Epoch 18/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 2.0250 - accuracy: 0.3776\n",
      "Epoch 19/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.9994 - accuracy: 0.3851\n",
      "Epoch 20/200\n",
      "56/75 [=====================>........] - ETA: 0s - loss: 1.9698 - accuracy: 0.3839\n",
      "Epoch 20: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.9723 - accuracy: 0.3834\n",
      "Epoch 21/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.9458 - accuracy: 0.3951\n",
      "Epoch 22/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.9263 - accuracy: 0.4051\n",
      "Epoch 23/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.9109 - accuracy: 0.4088\n",
      "Epoch 24/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.8874 - accuracy: 0.4147\n",
      "Epoch 25/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.8755 - accuracy: 0.4184\n",
      "Epoch 26/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.8605 - accuracy: 0.4209\n",
      "Epoch 27/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.8489 - accuracy: 0.4297\n",
      "Epoch 28/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.8344 - accuracy: 0.4285\n",
      "Epoch 29/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.8272 - accuracy: 0.4368\n",
      "Epoch 30/200\n",
      "63/75 [========================>.....] - ETA: 0s - loss: 1.8094 - accuracy: 0.4365\n",
      "Epoch 30: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.8172 - accuracy: 0.4393\n",
      "Epoch 31/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.8089 - accuracy: 0.4372\n",
      "Epoch 32/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.8003 - accuracy: 0.4481\n",
      "Epoch 33/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7927 - accuracy: 0.4468\n",
      "Epoch 34/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7864 - accuracy: 0.4472\n",
      "Epoch 35/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7789 - accuracy: 0.4493\n",
      "Epoch 36/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7712 - accuracy: 0.4589\n",
      "Epoch 37/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7658 - accuracy: 0.4564\n",
      "Epoch 38/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7608 - accuracy: 0.4589\n",
      "Epoch 39/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.7531 - accuracy: 0.4597\n",
      "Epoch 40/200\n",
      "68/75 [==========================>...] - ETA: 0s - loss: 1.7744 - accuracy: 0.4563\n",
      "Epoch 40: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7482 - accuracy: 0.4622\n",
      "Epoch 41/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7441 - accuracy: 0.4610\n",
      "Epoch 42/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7362 - accuracy: 0.4652\n",
      "Epoch 43/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7271 - accuracy: 0.4652\n",
      "Epoch 44/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7291 - accuracy: 0.4718\n",
      "Epoch 45/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7175 - accuracy: 0.4710\n",
      "Epoch 46/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7146 - accuracy: 0.4739\n",
      "Epoch 47/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7117 - accuracy: 0.4789\n",
      "Epoch 48/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.7030 - accuracy: 0.4723\n",
      "Epoch 49/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.7040 - accuracy: 0.4839\n",
      "Epoch 50/200\n",
      "57/75 [=====================>........] - ETA: 0s - loss: 1.7058 - accuracy: 0.4709\n",
      "Epoch 50: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6968 - accuracy: 0.4760\n",
      "Epoch 51/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6895 - accuracy: 0.4819\n",
      "Epoch 52/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6879 - accuracy: 0.4814\n",
      "Epoch 53/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6853 - accuracy: 0.4827\n",
      "Epoch 54/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6752 - accuracy: 0.4873\n",
      "Epoch 55/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6723 - accuracy: 0.4827\n",
      "Epoch 56/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6661 - accuracy: 0.4906\n",
      "Epoch 57/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6635 - accuracy: 0.4898\n",
      "Epoch 58/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.6550 - accuracy: 0.4935\n",
      "Epoch 59/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6606 - accuracy: 0.4885\n",
      "Epoch 60/200\n",
      "56/75 [=====================>........] - ETA: 0s - loss: 1.7039 - accuracy: 0.4888\n",
      "Epoch 60: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6466 - accuracy: 0.4977\n",
      "Epoch 61/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.6335 - accuracy: 0.4902\n",
      "Epoch 62/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6295 - accuracy: 0.4981\n",
      "Epoch 63/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.6227 - accuracy: 0.4998\n",
      "Epoch 64/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6157 - accuracy: 0.4998\n",
      "Epoch 65/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6077 - accuracy: 0.5019\n",
      "Epoch 66/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.6002 - accuracy: 0.5027\n",
      "Epoch 67/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5974 - accuracy: 0.5010\n",
      "Epoch 68/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5918 - accuracy: 0.4981\n",
      "Epoch 69/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5841 - accuracy: 0.5031\n",
      "Epoch 70/200\n",
      "64/75 [========================>.....] - ETA: 0s - loss: 1.5532 - accuracy: 0.5117\n",
      "Epoch 70: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5764 - accuracy: 0.5035\n",
      "Epoch 71/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5738 - accuracy: 0.5073\n",
      "Epoch 72/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5658 - accuracy: 0.5115\n",
      "Epoch 73/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5578 - accuracy: 0.5060\n",
      "Epoch 74/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5543 - accuracy: 0.5115\n",
      "Epoch 75/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5467 - accuracy: 0.5119\n",
      "Epoch 76/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5423 - accuracy: 0.5090\n",
      "Epoch 77/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5380 - accuracy: 0.5090\n",
      "Epoch 78/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5315 - accuracy: 0.5211\n",
      "Epoch 79/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5288 - accuracy: 0.5181\n",
      "Epoch 80/200\n",
      "74/75 [============================>.] - ETA: 0s - loss: 1.5257 - accuracy: 0.5232\n",
      "Epoch 80: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.5247 - accuracy: 0.5236\n",
      "Epoch 81/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5224 - accuracy: 0.5148\n",
      "Epoch 82/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5136 - accuracy: 0.5190\n",
      "Epoch 83/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5093 - accuracy: 0.5223\n",
      "Epoch 84/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5104 - accuracy: 0.5186\n",
      "Epoch 85/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5032 - accuracy: 0.5173\n",
      "Epoch 86/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4955 - accuracy: 0.5223\n",
      "Epoch 87/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4929 - accuracy: 0.5202\n",
      "Epoch 88/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4904 - accuracy: 0.5181\n",
      "Epoch 89/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4843 - accuracy: 0.5244\n",
      "Epoch 90/200\n",
      "75/75 [==============================] - ETA: 0s - loss: 1.4794 - accuracy: 0.5232\n",
      "Epoch 90: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4794 - accuracy: 0.5232\n",
      "Epoch 91/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4811 - accuracy: 0.5244\n",
      "Epoch 92/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4701 - accuracy: 0.5294\n",
      "Epoch 93/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4706 - accuracy: 0.5294\n",
      "Epoch 94/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4640 - accuracy: 0.5327\n",
      "Epoch 95/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4655 - accuracy: 0.5290\n",
      "Epoch 96/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4606 - accuracy: 0.5265\n",
      "Epoch 97/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4561 - accuracy: 0.5311\n",
      "Epoch 98/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4533 - accuracy: 0.5332\n",
      "Epoch 99/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4496 - accuracy: 0.5332\n",
      "Epoch 100/200\n",
      "74/75 [============================>.] - ETA: 0s - loss: 1.4505 - accuracy: 0.5308\n",
      "Epoch 100: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4485 - accuracy: 0.5307\n",
      "Epoch 101/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4429 - accuracy: 0.5357\n",
      "Epoch 102/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4405 - accuracy: 0.5403\n",
      "Epoch 103/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4379 - accuracy: 0.5407\n",
      "Epoch 104/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4341 - accuracy: 0.5373\n",
      "Epoch 105/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4319 - accuracy: 0.5482\n",
      "Epoch 106/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4246 - accuracy: 0.5382\n",
      "Epoch 107/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4308 - accuracy: 0.5457\n",
      "Epoch 108/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4217 - accuracy: 0.5419\n",
      "Epoch 109/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4199 - accuracy: 0.5474\n",
      "Epoch 110/200\n",
      "48/75 [==================>...........] - ETA: 0s - loss: 1.4046 - accuracy: 0.5495\n",
      "Epoch 110: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4129 - accuracy: 0.5474\n",
      "Epoch 111/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4150 - accuracy: 0.5444\n",
      "Epoch 112/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.4107 - accuracy: 0.5494\n",
      "Epoch 113/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.4058 - accuracy: 0.5524\n",
      "Epoch 114/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.4043 - accuracy: 0.5532\n",
      "Epoch 115/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3960 - accuracy: 0.5528\n",
      "Epoch 116/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.5457\n",
      "Epoch 117/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3907 - accuracy: 0.5524\n",
      "Epoch 118/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3948 - accuracy: 0.5578\n",
      "Epoch 119/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3892 - accuracy: 0.5582\n",
      "Epoch 120/200\n",
      "63/75 [========================>.....] - ETA: 0s - loss: 1.3912 - accuracy: 0.5541\n",
      "Epoch 120: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3875 - accuracy: 0.5549\n",
      "Epoch 121/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3820 - accuracy: 0.5569\n",
      "Epoch 122/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3817 - accuracy: 0.5540\n",
      "Epoch 123/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3834 - accuracy: 0.5565\n",
      "Epoch 124/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3761 - accuracy: 0.5640\n",
      "Epoch 125/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3766 - accuracy: 0.5611\n",
      "Epoch 126/200\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.3691 - accuracy: 0.5653\n",
      "Epoch 127/200\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.3671 - accuracy: 0.5590\n",
      "Epoch 128/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3670 - accuracy: 0.5665\n",
      "Epoch 129/200\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.3656 - accuracy: 0.5611\n",
      "Epoch 130/200\n",
      "64/75 [========================>.....] - ETA: 0s - loss: 1.3526 - accuracy: 0.5669\n",
      "Epoch 130: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.3604 - accuracy: 0.5640\n",
      "Epoch 131/200\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 1.3551 - accuracy: 0.5782\n",
      "Epoch 132/200\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.3548 - accuracy: 0.5690\n",
      "Epoch 133/200\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.3567 - accuracy: 0.5661\n",
      "Epoch 134/200\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.3542 - accuracy: 0.5649\n",
      "Epoch 135/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3471 - accuracy: 0.5732\n",
      "Epoch 136/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3520 - accuracy: 0.5665\n",
      "Epoch 137/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3430 - accuracy: 0.5741\n",
      "Epoch 138/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3431 - accuracy: 0.5766\n",
      "Epoch 139/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3393 - accuracy: 0.5699\n",
      "Epoch 140/200\n",
      "74/75 [============================>.] - ETA: 0s - loss: 1.3418 - accuracy: 0.5743\n",
      "Epoch 140: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3373 - accuracy: 0.5757\n",
      "Epoch 141/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3324 - accuracy: 0.5715\n",
      "Epoch 142/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3337 - accuracy: 0.5715\n",
      "Epoch 143/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3340 - accuracy: 0.5703\n",
      "Epoch 144/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3268 - accuracy: 0.5770\n",
      "Epoch 145/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3275 - accuracy: 0.5728\n",
      "Epoch 146/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3225 - accuracy: 0.5811\n",
      "Epoch 147/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3244 - accuracy: 0.5786\n",
      "Epoch 148/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3225 - accuracy: 0.5761\n",
      "Epoch 149/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3202 - accuracy: 0.5832\n",
      "Epoch 150/200\n",
      "71/75 [===========================>..] - ETA: 0s - loss: 1.3145 - accuracy: 0.5805\n",
      "Epoch 150: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3157 - accuracy: 0.5820\n",
      "Epoch 151/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3110 - accuracy: 0.5857\n",
      "Epoch 152/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3114 - accuracy: 0.5774\n",
      "Epoch 153/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3051 - accuracy: 0.5924\n",
      "Epoch 154/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3053 - accuracy: 0.5891\n",
      "Epoch 155/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3045 - accuracy: 0.5874\n",
      "Epoch 156/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2994 - accuracy: 0.5866\n",
      "Epoch 157/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2986 - accuracy: 0.5899\n",
      "Epoch 158/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2966 - accuracy: 0.5878\n",
      "Epoch 159/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.3038 - accuracy: 0.5857\n",
      "Epoch 160/200\n",
      "75/75 [==============================] - ETA: 0s - loss: 1.2937 - accuracy: 0.5832\n",
      "Epoch 160: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2937 - accuracy: 0.5832\n",
      "Epoch 161/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2957 - accuracy: 0.5903\n",
      "Epoch 162/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2880 - accuracy: 0.5899\n",
      "Epoch 163/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2904 - accuracy: 0.5861\n",
      "Epoch 164/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2882 - accuracy: 0.5916\n",
      "Epoch 165/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2868 - accuracy: 0.5895\n",
      "Epoch 166/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2783 - accuracy: 0.5941\n",
      "Epoch 167/200\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.2840 - accuracy: 0.5899\n",
      "Epoch 168/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2787 - accuracy: 0.5932\n",
      "Epoch 169/200\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.2768 - accuracy: 0.5932\n",
      "Epoch 170/200\n",
      "70/75 [===========================>..] - ETA: 0s - loss: 1.2848 - accuracy: 0.5933\n",
      "Epoch 170: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2779 - accuracy: 0.5966\n",
      "Epoch 171/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2737 - accuracy: 0.5995\n",
      "Epoch 172/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2703 - accuracy: 0.5928\n",
      "Epoch 173/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2708 - accuracy: 0.5924\n",
      "Epoch 174/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2716 - accuracy: 0.5891\n",
      "Epoch 175/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2678 - accuracy: 0.5916\n",
      "Epoch 176/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2670 - accuracy: 0.5891\n",
      "Epoch 177/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2613 - accuracy: 0.5949\n",
      "Epoch 178/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2621 - accuracy: 0.5991\n",
      "Epoch 179/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2639 - accuracy: 0.5953\n",
      "Epoch 180/200\n",
      "73/75 [============================>.] - ETA: 0s - loss: 1.2585 - accuracy: 0.5950\n",
      "Epoch 180: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.2586 - accuracy: 0.5945\n",
      "Epoch 181/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2516 - accuracy: 0.5978\n",
      "Epoch 182/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2565 - accuracy: 0.5974\n",
      "Epoch 183/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2577 - accuracy: 0.6049\n",
      "Epoch 184/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2499 - accuracy: 0.5970\n",
      "Epoch 185/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2480 - accuracy: 0.5937\n",
      "Epoch 186/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2481 - accuracy: 0.5978\n",
      "Epoch 187/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2464 - accuracy: 0.6024\n",
      "Epoch 188/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2431 - accuracy: 0.6020\n",
      "Epoch 189/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2475 - accuracy: 0.6024\n",
      "Epoch 190/200\n",
      "75/75 [==============================] - ETA: 0s - loss: 1.2382 - accuracy: 0.6003\n",
      "Epoch 190: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2382 - accuracy: 0.6003\n",
      "Epoch 191/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2401 - accuracy: 0.6041\n",
      "Epoch 192/200\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 1.2350 - accuracy: 0.6024\n",
      "Epoch 193/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2350 - accuracy: 0.6049\n",
      "Epoch 194/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2328 - accuracy: 0.6033\n",
      "Epoch 195/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2346 - accuracy: 0.5974\n",
      "Epoch 196/200\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 1.2343 - accuracy: 0.5962\n",
      "Epoch 197/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2283 - accuracy: 0.6033\n",
      "Epoch 198/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2319 - accuracy: 0.6016\n",
      "Epoch 199/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2271 - accuracy: 0.6033\n",
      "Epoch 200/200\n",
      "72/75 [===========================>..] - ETA: 0s - loss: 1.2301 - accuracy: 0.5990\n",
      "Epoch 200: saving model to ./ML_Weight_Checkpoints\\seg1_basic_model.h5\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2284 - accuracy: 0.6008\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=200, callbacks=[cp_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - loss: 1.2603 - accuracy: 0.6062 - 279ms/epoch - 11ms/step\n",
      "Loss: 1.260319471359253, Accuracy: 0.606249988079071\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.08695652173913043, 0.7692307692307693, 0.7000000000000001,\n        0.10144927536231885, 0.5144927536231884, 0.08695652173913043,\n        0.9420289855072463, 0.19565217391304343, 0.3043478260869565, 0.0,\n        0.3550724637681159, 0.9999999999999998, 0.07971014492753623,\n        0.5507246376811593]], dtype=object)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model with data from a random beer, simulating user's preference data\n",
    "user_input = beers_df.sample().iloc[0][1:15].values\n",
    "user_input = user_input.reshape(1,-1)\n",
    "user_input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "Predicted Beer Style: IPA\n"
     ]
    }
   ],
   "source": [
    "# Output beer style based on taste profile inputs\n",
    "index = nn.predict(np.asarray(user_input).astype(np.float64)).argmax()\n",
    "print(f\"Predicted Beer Style: {encode_df.columns[index].split('_', 1)[1]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mlenv",
   "language": "python",
   "display_name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}